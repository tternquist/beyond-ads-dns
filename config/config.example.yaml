server:
  listen:
    - "0.0.0.0:53"
  protocols:
    - udp
    - tcp
  read_timeout: "5s"
  write_timeout: "5s"
  # reuse_port: true   # default: SO_REUSEPORT for multi-listener performance (set false to disable)
  # reuse_port_listeners: 4  # default: NumCPU capped 1-16 when reuse_port is true

# Resolver strategy: failover | load_balance | weighted (weighted uses response-time EWMA to prefer faster upstreams)
resolver_strategy: failover
# upstream_timeout: "10s"  # Timeout for UDP/TCP/TLS upstream queries (default 10s). Increase if seeing "i/o timeout" on refresh.
# upstream_backoff: "30s"  # Skip upstream for this duration after connection/timeout failure (omit = 30s, "0" = disabled)
# upstream_conn_pool_idle_timeout: "30s"  # Max time to reuse idle TCP/TLS conn (default 30s). 0 = no limit. Reduces EOF/write errors on Pi.
# upstream_conn_pool_validate_before_reuse: true  # Validate pooled conns before use (default true). Set false to disable.
# Upstreams: plain DNS (host:port), DoT (tls://host:port), or DoH (https://host/path)
upstreams:
  - name: cloudflare
    address: "1.1.1.1:53"
  - name: google
    address: "8.8.8.8:53"
  - name: quad9
    address: "9.9.9.9:53"
  # DoT (DNS over TLS) - encrypted upstream:
  # - name: cloudflare-dot
  #   address: "tls://1.1.1.1:853"
  # DoH (DNS over HTTPS) - encrypted upstream:
  # - name: cloudflare-doh
  #   address: "https://cloudflare-dns.com/dns-query"

blocklists:
  refresh_interval: "6h"
  sources:
    - name: hagezi-pro
      url: "https://raw.githubusercontent.com/hagezi/dns-blocklists/main/domains/pro.txt"
  allowlist: []
  denylist: []
  # Scheduled pause: don't block during work hours (e.g. allow work tools)
  # scheduled_pause:
  #   enabled: true
  #   start: "09:00"
  #   end: "17:00"
  #   days: [1, 2, 3, 4, 5]  # Mon-Fri (0=Sun, 6=Sat)
  # Family time: block selected services during scheduled hours (e.g. dinner, homework)
  # family_time:
  #   enabled: true
  #   start: "17:00"
  #   end: "20:00"
  #   days: [0, 1, 2, 3, 4, 5, 6]  # All days
  #   services: ["tiktok", "youtube", "roblox", "instagram"]  # Service IDs from blockable services
  #   domains: []  # Optional: additional domains to block
  # Health check: validate blocklist URLs before apply
  # health_check:
  #   enabled: true
  #   fail_on_any: true   # If true, apply fails when any source fails

# Local DNS records - returned without upstream lookup, work when internet is down
# local_records:
#   - name: "router.local"
#     type: "A"
#     value: "192.168.1.1"
#   - name: "nas.home"
#     type: "A"
#     value: "192.168.1.10"

cache:
  redis:
    address: "redis:6379"
    db: 0
    password: ""
    # lru_size: 10000  # L0 cache size (0 to disable)
    # hit_counter_max_entries: 10000  # Local hit counter size, LRU eviction (0 = default)
    # mode: "standalone" (default) | "sentinel" | "cluster"
    # For Sentinel HA (or use env: REDIS_MODE, REDIS_MASTER_NAME, REDIS_SENTINEL_ADDRS):
    # mode: sentinel
    # master_name: mymaster
    # sentinel_addrs: ["sentinel1:26379", "sentinel2:26379"]
    # For Redis Cluster (or use env: REDIS_MODE, REDIS_CLUSTER_ADDRS):
    # mode: cluster
    # cluster_addrs: ["redis1:6379", "redis2:6379", "redis3:6379"]
  min_ttl: "300s"
  max_ttl: "1h"
  negative_ttl: "5m"
  # servfail_backoff: "60s"       # Back off before retrying after SERVFAIL (security/misconfig indicator)
  # servfail_refresh_threshold: 10  # Stop retrying refresh after this many SERVFAILs (0 = no limit)
  # servfail_log_interval: "60s"  # Min interval between servfail log messages per cache key (0 = no limit, default: servfail_backoff)
  # refresh_upstream_fail_log_interval: "60s"  # Min interval between "refresh upstream failed" logs when network down (0 = no limit, default: 60s)
  # respect_source_ttl: false      # When true, don't extend TTL with min_ttl (strict source TTL)
  refresh:
    enabled: true
    hit_window: "1m"
    hot_threshold: 20
    min_ttl: "30s"
    hot_ttl: "2m"
    serve_stale: true
    stale_ttl: "1h"
    expired_entry_ttl: "30s"  # TTL in DNS response when serving expired entries
    lock_ttl: "10s"
    max_inflight: 50
    sweep_interval: "15s"
    sweep_window: "1m"
    max_batch_size: 2000
    sweep_min_hits: 1
    sweep_hit_window: "48h"
    # batch_stats_window: "2h"  # window for dynamic batch size stats (default 2h)
    # hit_count_sample_rate: 1.0  # fraction of hits to count (0.01-1.0). Use <1.0 to reduce Redis load at high QPS.

response:
  blocked: "nxdomain"
  blocked_ttl: "1h"

request_log:
  enabled: false
  directory: "logs"
  filename_prefix: "dns-requests"
  # format: "text" (default) or "json" for structured logs with query_id, qname, outcome, latency
  format: "text"

query_store:
  enabled: true
  address: "http://clickhouse:8123"
  database: "beyond_ads"
  table: "dns_queries"
  username: "beyondads"
  password: "beyondads"
  flush_to_store_interval: "5s"  # How often the app sends buffered events to ClickHouse
  flush_to_disk_interval: "5s"   # How often ClickHouse flushes async inserts to disk
  batch_size: 2000
  retention_hours: 168  # Hours to keep query analytics data (168 = 7 days). Use 12, 24 for sub-day (e.g. Pi)
  # max_size_mb: 56   # Omit for unlimited. With tmpfs: tmpfs_mb − 200 (e.g. 56 for 256MB tmpfs on Pi); oldest partitions dropped when over.
  sample_rate: 1.0   # Fraction of queries to record (0.0-1.0). 1.0 = all. Use <1.0 to reduce load at scale.
  # anonymize_client_ip: "none" | "hash" | "truncate"  # For GDPR/privacy: hash (SHA256 prefix) or truncate (/24 IPv4, /64 IPv6)

control:
  enabled: true
  listen: "0.0.0.0:8081"
  token: ""
# Structured logging (log/slog). Configurable in Metrics UI: Settings → Application Logging.
# Single log level controls both stdout output and Error Viewer buffer.
# logging:
#   format: "text"   # "text" (human-readable, default) or "json" (for Grafana/Loki)
#   level: "warning" # debug | info | warn | error. Controls stdout and Error Viewer.
#   trace_events: [] # Optional: event names to trace at runtime. Updatable via UI/API without restart.
#     # - refresh_upstream  # Trace background refresh requests to upstream DNS

# DoH/DoT server: accept encrypted DNS from clients (requires TLS certs)
# In Docker with Let's Encrypt, set DOH_DOT_ENABLED=true (see examples/letsencrypt-docker-compose)
# doh_dot_server:
#   enabled: true
#   cert_file: "/path/to/fullchain.pem"
#   key_file: "/path/to/privkey.pem"
#   dot_listen: "0.0.0.0:853"   # DoT (DNS over TLS)
#   doh_listen: "0.0.0.0:8443"  # DoH (DNS over HTTPS) - use 443 if not sharing with web UI
#   doh_path: "/dns-query"

# Multi-instance sync: one primary, any number of replicas
# Primary: replicas pull config via API tokens
# Replica: receives DNS-affecting config from primary; can tune cache/query store locally
# sync:
#   role: primary  # or replica
#   enabled: false
#   # Primary: list of tokens for replicas (id = token value, name = label)
#   tokens:
#     - id: "your-secret-token-here"
#       name: "Replica A"
#       created_at: "2025-02-13T12:00:00Z"
#       last_used: ""
#   # Replica only:
#   primary_url: "http://primary-host:8081"
#   sync_token: "your-secret-token-here"
#   sync_interval: "60s"
#   stats_source_url: "http://localhost:80"  # optional: web server URL for response distribution/latency in Multi-Instance view (use port 80, not 8080)

# Optional: Override the hostname displayed in the UI
# If not set, the system hostname will be used
ui:
  hostname: ""


# Webhooks: HTTP POST on block/error events. Supports multiple targets per event type.
# webhooks:
#   on_block:
#     enabled: true
#     rate_limit_max_messages: 60   # max webhooks in timeframe; -1 = unlimited
#     rate_limit_timeframe: "1m"   # e.g. 1m, 5m, 1h
#     targets:
#       - url: "https://example.com/webhook"
#         target: "default"   # raw JSON. Use "discord" for Discord embeds.
#         context:
#           tags: ["production", "dns"]
#           environment: "prod"
#       - url: "https://discord.com/api/webhooks/YOUR_ID/YOUR_TOKEN"
#         target: "discord"
#   on_error:
#     enabled: true
#     targets:
#       - url: "https://discord.com/api/webhooks/YOUR_ID/YOUR_TOKEN"
#         target: "discord"
#         context:
#           tags: ["alerts"]

# Client identification: map client IPs to friendly names for per-device analytics.
# Enables "Which device queries X?" in the Queries tab. Manage via Metrics UI → Clients.
# Supports legacy map format (IP → name) or list format with group assignment.
# client_identification:
#   enabled: true
#   # Legacy map format:
#   # clients:
#   #   "192.168.1.10": "kids-phone"
#   #   "192.168.1.11": "laptop"
#   # List format with groups (for parental controls):
#   clients:
#     - ip: "192.168.1.10"
#       name: "Kids Tablet"
#       group_id: "kids"
#     - ip: "192.168.1.11"
#       name: "Adults Phone"
#       group_id: "adults"
#
# Client groups: organize clients for per-group blocklists (parental controls).
# Groups are referenced by id in client_identification.clients.group_id.
# Each group can use the global blocklist (inherit_global: true) or have its own.
# client_groups:
#   - id: "kids"
#     name: "Kids"
#     description: "Children's devices - strict filtering"
#     blocklist:
#       inherit_global: false
#       sources:
#         - name: "hagezi-pro-plus"
#           url: "https://raw.githubusercontent.com/hagezi/dns-blocklists/main/domains/pro.plus.txt"
#       allowlist: []
#       denylist: ["roblox.com"]
#       family_time:  # Block services during scheduled hours (group-level)
#         enabled: true
#         start: "17:00"
#         end: "20:00"
#         days: [0, 1, 2, 3, 4, 5, 6]
#         services: ["tiktok", "youtube", "roblox", "instagram"]
#   - id: "adults"
#     name: "Adults"
#     description: "Adult devices - use global blocklist"
#     blocklist:
#       inherit_global: true

# Safe search: force safe search for Google and Bing (parental controls)
# safe_search:
#   enabled: true
#   google: true
#   bing: true
